import requests
from bs4 import BeautifulSoup
import csv

def scrape_dark_web(url):
    response = requests.get(url)  #here we are sending a http get request to the input url

    if response.status_code == 200: #.status_code is a part of the requests module in Python
        soup = BeautifulSoup(response.text,'html.parser')   #here we are Parsing the HTML content using BeautifulSoup & detailed info in notes

        list_items = soup.find_all('li')
        for item in list_items:
            item_text = item.get_text()  # Get the text content of the list item
            print(item_text.strip())  # Print the text content of each list item,removing leading and trailing whitespace

    else:
        print("Failed to scrape data from the URL:", url)

if __name__ == "__main__":
    url = "http://zqktlwiuavvvqqt4ybvgvi7tyo4hjl5xgfuvpdf6otjiycgwqbym2qad.onion/wiki/index.php/Main_Page"
    scrape_dark_web(url)

----------------------------------------------------------------scraper.py - above code------------------------------------------------------

data_handler.py :-

from transformers import BertForSequenceClassification, BertTokenizer
import torch
import numpy as np

CLASS_NAMES = {
     0: 'Drugs',
     1: 'Library Information',
     2: 'Counterfeit Products',
     3: 'Substances for Drugs',
     4: 'Services',
         5: 'Services/Money',
         6: 'Accounts',
         7: 'Drugs paraphernalia',
         8: 'Cryptocurrency',
         9: 'Violence',
         10: 'Counterfeit Personal-Identification',
         11: 'Leaked Data',
         12: 'Counterfeit Money',
         13: 'Counterfeit Other',
         14: 'Counterfeit Credit-Cards',
         15: 'Social Network',
         16: 'Porno',
         17: 'Counterfeit Personal Identification',
         18: 'Counterfeit Coupons',
         19: 'Fraud',
         20: 'Drugs Paraphernalia'
    }

    SAVED_MODEL = "D:\cyber-security\projects\DARK WEB RECONNISANCE\darkweb_recon\home\mchtcModel"
    tokenizer = BertTokenizer.from_pretrained(SAVED_MODEL, do_lower_case=True)

    N_labels = 21
    model = BertForSequenceClassification.from_pretrained(SAVED_MODEL,
                                                          num_labels=N_labels,
                                                          output_attentions=False,
                                                          output_hidden_states=False)
    model.eval()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    def predict(input_strings, device="cuda" if torch.cuda.is_available() else "cpu", batch_size=32):
        test_pred = []
        test_loss = 0

        # Tokenize input strings
        tokenizer_out = tokenizer.batch_encode_plus(input_strings, padding=True, truncation=True, return_tensors="pt")
        input_ids = tokenizer_out['input_ids']
        att_mask = tokenizer_out['attention_mask']

        # Load input data onto the specified device
        input_ids = input_ids.to(device)
        att_mask = att_mask.to(device)

        # Generate predictions
        with torch.no_grad():
            outputs = model(input_ids=input_ids, attention_mask=att_mask)

            # Extract logits from the output
            logits = outputs.logits

            # Get predicted labels by selecting the index with the maximum probability
            predictions = np.argmax(logits.cpu().numpy(), axis=-1)
            predictions = [CLASS_NAMES[labels] for labels in predictions]
        return predictions

    input_strings = ["guns armoury glock", "marijuana cocaine"]
    predicted_labels = predict(input_strings)
    print(predicted_labels)

--------------------------------------------------------------------------------------------------------------------------------------

views.py :
from django.shortcuts import render
from darkweb_recon.scraper import scrape_dark_web, parse_data
from darkweb_recon.home.data_handler import predict
# Create your views here.
def index(request):
    return render(request,'index.html')

def about(request):
    return render(request,'about.html')


def check_suspicious(request):
    if request.method == 'POST':
        # Get the URL input from the form
        url = request.POST.get('url')

        # Call the function in scraper.py to scrape the website and save data to CSV
        scrape_dark_web(url)

        # Call the predict function from data_handler.py to check if the scraped data is suspicious
        input_strings = parse_data(scraped_file_path)  # Define input strings from the scraped data (you need to parse the CSV file)
        predicted_labels = predict(input_strings)

        # Check if any predicted label is suspicious
        is_suspicious = any(label in ['Drugs', 'Violence', 'Porno'] for label in predicted_labels)

        # Render the result template with the result
        return render(request, 'index.html', {'is_suspicious': is_suspicious, 'url': url})
    else:
        # If the request method is not POST, render the home page
        return render(request, 'index.html')